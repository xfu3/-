{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mp\n",
    "from matplotlib import cm\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from xgboost import XGBClassifier,XGBRegressor,plot_importance\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,cross_validate,cross_val_score,train_test_split\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(x,n):\n",
    "    val = 0\n",
    "    if x > n:\n",
    "        val = 1\n",
    "    return val\n",
    "\n",
    "class stats_met:\n",
    "    \"\"\"\n",
    "    定义一个类，用来分类器的性能度量\n",
    "    \"\"\"\n",
    "    def __init__(self, labels, scores):\n",
    "        \"\"\"\n",
    "        :param labels:数组类型，真实的标签\n",
    "        :param scores:数组类型，分类器的得分\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.scores = scores\n",
    "        self.TP, self.FP, self.FN, self.TN = self.get_confusion_matrix()\n",
    "    \n",
    "    def accuracy(self):\n",
    "        \"\"\"\n",
    "        :return: 准确率\n",
    "        \"\"\"\n",
    "        accuracy = (self.TP + self.TN) / (self.TP + self.FN + self.FP + self.TN)\n",
    "        \n",
    "        return accuracy\n",
    " \n",
    "    def precision(self):\n",
    "        \"\"\"\n",
    "        :return: 精准度\n",
    "        \"\"\"\n",
    "        try:\n",
    "            precision = self.TP / (self.TP + self.FP)\n",
    "        except ZeroDivisionError:\n",
    "            precision = np.nan\n",
    "        \n",
    "        return precision\n",
    " \n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        :return: 召回率\n",
    "        \"\"\"\n",
    "        try:\n",
    "            recall = self.TP / (self.TP + self.FN)\n",
    "        except ZeroDivisionError:\n",
    "            recall = np.nan\n",
    "        \n",
    "        return recall\n",
    "    \n",
    "    def f_beta(self,beta):\n",
    "        precision = self.precision()\n",
    "        recall = self.recall()\n",
    "        \n",
    "        f_score = (1+beta**2)*((precision*recall/((beta**2)*precision+recall)))\n",
    "        return f_score\n",
    " \n",
    "    def get_confusion_matrix(self):\n",
    "        \"\"\"\n",
    "        计算混淆矩阵\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        tp, fp, fn, tn = 0., 0., 0., 0.\n",
    "        for i in range(len(self.labels)):\n",
    "            if self.labels[i] == 1 and self.scores[i] == 1:\n",
    "                tp += 1\n",
    "            elif self.labels[i] == 0 and self.scores[i] == 1:\n",
    "                fp += 1\n",
    "            elif self.labels[i] == 1 and self.scores[i] == 0:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        return [tp, fp, fn, tn]\n",
    "    \n",
    "    def get_eval_metrics(self):\n",
    "        print(\"Precision = {:0.3f},Recall = {:0.3f}, F_score = {:0.3f}\".format(self.precision(),self.recall(),self.f_beta(beta = 0.3)))\n",
    "    \n",
    "        \n",
    "    \n",
    "## Adjust graph spines\n",
    "def adjust_spines(ax, spines):\n",
    "    for loc, spine in ax.spines.items():\n",
    "        if loc in spines:\n",
    "            spine.set_position(('outward', 20))  # outward by 10 points\n",
    "            #spine.set_smart_bounds(True)\n",
    "        else:\n",
    "            spine.set_color('none')  # don't draw spine\n",
    "            \n",
    "## function of getting the optimized paramters and score\n",
    "def hypertuning_rscv(est,p_distr,nbr_iter,X,y):\n",
    "    rdmsearch = RandomizedSearchCV(est, param_distributions=p_distr,n_jobs=-1,scoring = 'roc_auc', n_iter=nbr_iter,cv=5)\n",
    "    \n",
    "    rdmsearch.fit(X,y)\n",
    "    ht_params = rdmsearch.best_params_\n",
    "    ht_score = rdmsearch.best_score_\n",
    "    return(ht_params,ht_score)\n",
    "\n",
    "def sort_feature_importance(importance,names):\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    fea_data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(fea_data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'],ascending = True,ignore_index=True,inplace = True)\n",
    "    return fi_df\n",
    "\n",
    "\n",
    "def visualization(recall,precision,f_score,threshold,threshold_max):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,9))\n",
    "\n",
    "    colors = [plt.cm.tab10(i/float(5)) for i in range(3)]\n",
    "    \n",
    "    min_y = round(min(f_score),2)\n",
    "    max_y = round(max(f_score),2)\n",
    "    \n",
    "    min_y_per = round(min(f_score*100))\n",
    "    max_y_per = round(max(f_score*100))\n",
    "    \n",
    "    ax.plot(threshold,f_score,alpha = 0.3,color = colors[1],linewidth = \"1\")\n",
    "    ax.scatter(threshold,f_score,alpha = 0.9,color = colors[1],s = 0.38)\n",
    "    \n",
    "    ax.axvline(thre_max, color=\"black\", linestyle=\"dashed\")\n",
    "\n",
    "    ax.tick_params(axis= \"both\",direction = 'out',which='major', length=6.8,width=1, color='k',labelsize = 18)\n",
    "    ax.set_xticks([0.05*i for i in range(9,13)])\n",
    "    ax.set_yticks([0.01*i for i in range(min_y_per,max_y_per+1)])\n",
    "    ax.set_ylabel(\"F score\",size = 25,labelpad=12)\n",
    "    ax.set_xlabel(\"Threshold\",size = 25,labelpad=12)\n",
    "    ax.set_title(\"F_0.3 vs threshold\",size = 30)\n",
    "\n",
    "    ax.spines['left'].set_bounds(0.52,0.56)\n",
    "    ax.spines['bottom'].set_bounds(0.45,0.6)\n",
    "    ax.legend(fontsize = 25)\n",
    "\n",
    "    adjust_spines(ax, ['left', 'bottom'])\n",
    "    \n",
    "### K fold target encoding for training test\n",
    "class KFoldTargetEncoderTrain(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self, colnames,targetName,n_fold=5,verbosity=True,discardOriginal_col=False):\n",
    "\n",
    "        self.colnames = colnames\n",
    "        self.targetName = targetName\n",
    "        self.n_fold = n_fold\n",
    "        self.verbosity = verbosity\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self,X):\n",
    "\n",
    "        assert(type(self.targetName) == str)\n",
    "        assert(type(self.colnames) == str)\n",
    "        assert(self.colnames in X.columns)\n",
    "        assert(self.targetName in X.columns)\n",
    "\n",
    "        mean_of_target = X[self.targetName].mean()\n",
    "        kf = KFold(n_splits = self.n_fold, shuffle = True, random_state=2019)\n",
    "\n",
    "\n",
    "\n",
    "        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n",
    "        X[col_mean_name] = np.nan\n",
    "\n",
    "        for tr_ind, val_ind in kf.split(X):\n",
    "            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n",
    "\n",
    "            X.loc[X.index[val_ind], col_mean_name] = X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n",
    "\n",
    "        X[col_mean_name].fillna(mean_of_target, inplace = True)\n",
    "\n",
    "        if self.verbosity:\n",
    "\n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,\n",
    "                                                                                      self.targetName,\n",
    "                                                                                      np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n",
    "        if self.discardOriginal_col:\n",
    "            X = X.drop(self.targetName, axis=1)\n",
    "            \n",
    "\n",
    "        return(X)\n",
    "    \n",
    "### K Fold target encoding for test set\n",
    "class KFoldTargetEncoderTest(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,train,colNames,encodedName):\n",
    "        \n",
    "        self.train = train\n",
    "        self.colNames = colNames\n",
    "        self.encodedName = encodedName\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        mean =  self.train[[self.colNames,\n",
    "                self.encodedName]].groupby(\n",
    "                                self.colNames).mean().reset_index() \n",
    "        \n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.colNames]] = row[self.encodedName]\n",
    "        X[self.encodedName] = X[self.colNames]\n",
    "        X = X.replace({self.encodedName: dd})\n",
    "    \n",
    "        return(X)\n",
    "    \n",
    "def model_train(pipe,param_dist,nbr_iter,X_train,y_train,target_train,X_cv,y_cv,target_cv,X_val,y_val,target_val,X_test,y_test,target_test,plot = False,plot_fea = False):\n",
    "    ## -------------------model training-------------------\n",
    "    start_time = time.time()\n",
    "    \n",
    "    random_params, random_score = hypertuning_rscv(pipe,param_dist,nbr_iter, X_cv, y_cv)\n",
    "    \n",
    "    classifier_1 = pipe.set_params(**random_params)\n",
    "    classifier_1.fit(X_cv,y_cv)\n",
    "    \n",
    "    \n",
    "    print(\"The selected set of hyperparameters[xgb] is {}.\".format(random_params))\n",
    "    ##-------------------F score extraction-------------------\n",
    "    \n",
    "    #pred_val = np.array(classifier_1.predict(X_val))\n",
    "    prob_val = np.array(classifier_1.predict_proba(X_val)[:,1])\n",
    "\n",
    "    interval = 0.2/10000\n",
    "    threshold = [0.4 + i*interval for i in range(10001)]\n",
    "\n",
    "    frame = pd.DataFrame()\n",
    "    scores_cla = [1]*X_val.shape[0]\n",
    "    \n",
    "    for i in threshold:    \n",
    "        scores_cla = [1 if j > i else 0 for j in prob_val]\n",
    "        \n",
    "        scores_val = list(scores_cla)\n",
    "        label_val = list(target_val)\n",
    "        \n",
    "        cl = stats_met(label_val,scores_val)\n",
    "        \n",
    "        precision = cl.precision()\n",
    "        \n",
    "        recall = cl.recall()\n",
    "        \n",
    "        f_beta = cl.f_beta(beta = 0.3)\n",
    "\n",
    "        frame_row = {\"threshold\":i,\"Precision\":precision,\"Recall\":recall,\"F_beta\":f_beta}\n",
    "        frame = frame.append(frame_row,ignore_index=True)\n",
    "    \n",
    "    \n",
    "    threshold_max = frame.loc[frame.F_beta == max(frame.F_beta),\"threshold\"].iloc[0]\n",
    "    \n",
    "    scores_val = [1 if j > threshold_max else 0 for j in prob_val]\n",
    "\n",
    "    labels_val = list(target_val)\n",
    "    \n",
    "    val_metrics = stats_met(labels_val,scores_val)\n",
    "    \n",
    "    print(\"---The metric scores of the validation set is---\")\n",
    "    val_metrics.get_eval_metrics()\n",
    "    \n",
    "    if plot:\n",
    "        threshold = frame[\"threshold\"]\n",
    "        f_score = frame[\"F_beta\"]\n",
    "        precision = frame[\"Precision\"]\n",
    "        recall = frame[\"Recall\"]\n",
    "\n",
    "        visualization(recall,precision,f_score,threshold,threshold_max)\n",
    "    \n",
    "    if plot_fea:\n",
    "        plt.rcParams['figure.figsize'] = [18,18]\n",
    "        plot_importance(classifier_1[2])\n",
    "        plt.show()  \n",
    "    \n",
    "    ## -------------------Training the whole dataset-------------------\n",
    "    classifier_2 = pipe.set_params(**random_params)\n",
    "    classifier_2.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "    pred_test = classifier_2.predict_proba(X_test)[:,1]\n",
    "\n",
    "    classifier_2.fit(X_train,y_train)\n",
    "\n",
    "    sma_barr_scores_1 = list(pred_test) \n",
    "    sma_barr_scores_2 = [1 if k > threshold_max else 0 for k in sma_barr_scores_1]\n",
    "\n",
    "    labels_test = list(target_test) ## delete expectancy\n",
    "    scores_test = sma_barr_scores_2\n",
    "\n",
    "    test_metrics = stats_met(labels_test,scores_test)\n",
    "\n",
    "    print(\"---The metric scores of the test set is---\")\n",
    "    test_metrics.get_eval_metrics()\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    \n",
    "class XGBoostWithEarlyStop(BaseEstimator):\n",
    "    def __init__(self, early_stopping_rounds=8, test_size=0.1,\n",
    "                 eval_metric='auc',**estimator_params):\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.test_size = test_size\n",
    "        self.eval_metric=eval_metric='auc'        \n",
    "        if self.estimator is not None:\n",
    "            self.set_params(**estimator_params)\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        return self.estimator.set_params(**params)\n",
    "\n",
    "    def get_params(self, **params):\n",
    "        return self.estimator.get_params()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=self.test_size)\n",
    "        self.estimator.fit(x_train, y_train,\n",
    "                           early_stopping_rounds=self.early_stopping_rounds,\n",
    "                           eval_metric=self.eval_metric, eval_set=[(x_val, y_val)])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "class XGBoostRegressorWithEarlyStop(XGBoostWithEarlyStop):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.estimator = XGBRegressor()\n",
    "        super(XGBoostRegressorWithEarlyStop, self).__init__(*args, **kwargs)\n",
    "\n",
    "class XGBoostClassifierWithEarlyStop(XGBoostWithEarlyStop):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.estimator = XGBClassifier()\n",
    "        super(XGBoostClassifierWithEarlyStop, self).__init__(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_poked = pd.read_csv('july_poked.csv',encoding = \"GBK\")\n",
    "aug_small_bucket = pd.read_csv('aug_small_bucket.csv',encoding = \"GBK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_poked.fillna(0,inplace = True)\n",
    "aug_small_bucket.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_poked[\"key_2\"] = july_poked[\"city_code\"].astype(\"str\") + \"_\" + july_poked[\"l2_code\"].astype(\"str\") \n",
    "aug_small_bucket[\"key_2\"] = aug_small_bucket[\"city_code\"].astype(\"str\") + \"_\" + aug_small_bucket[\"l2_code\"].astype(\"str\") \n",
    "\n",
    "july_poked[\"key_3\"] = july_poked[\"city_code\"].astype(\"str\") + \"_\" + july_poked[\"l2_code\"].astype(\"str\") + \"_\" + july_poked[\"com_id\"].astype(\"str\")\n",
    "aug_small_bucket[\"key_3\"] = aug_small_bucket[\"city_code\"].astype(\"str\") + \"_\" + aug_small_bucket[\"l2_code\"].astype(\"str\") + \"_\" + aug_small_bucket[\"com_id\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_small_poked = july_poked.loc[july_poked[\"key_2\"].isin(list(aug_small_bucket[\"key_2\"].unique())),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_small_bucket_poked = aug_small_bucket.loc[aug_small_bucket.is_poked == \"poked\",:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_small_poked[[\"is_paid\",\"is_del\"]] = july_small_poked[[\"is_paid\",\"is_del\"]].apply(lambda x: x.astype('str'))\n",
    "aug_small_bucket_poked[[\"is_paid\",\"is_del\"]] = aug_small_bucket_poked[[\"is_paid\",\"is_del\"]].apply(lambda x: x.astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_small_poked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training data\n",
    "july_small_poked.loc[july_small_poked[\"is_paid\"] == \"paid\",\"is_paid\"] = 1\n",
    "july_small_poked.loc[july_small_poked[\"is_paid\"] == \"unpaid\",\"is_paid\"] = 0\n",
    "\n",
    "july_small_poked.loc[july_small_poked[\"is_del\"] == \"deleted\",\"is_del\"] = 1\n",
    "july_small_poked.loc[july_small_poked[\"is_del\"] == \"undeleted\",\"is_del\"] = 0\n",
    "\n",
    "## testing data\n",
    "aug_small_bucket_poked.loc[aug_small_bucket_poked[\"is_paid\"] == \"paid\",\"is_paid\"] = 1\n",
    "aug_small_bucket_poked.loc[aug_small_bucket_poked[\"is_paid\"] == \"unpaid\",\"is_paid\"] = 0\n",
    "\n",
    "aug_small_bucket_poked.loc[aug_small_bucket_poked[\"is_del\"] == \"deleted\",\"is_del\"] = 1\n",
    "aug_small_bucket_poked.loc[aug_small_bucket_poked[\"is_del\"] == \"undeleted\",\"is_del\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sub_training and validation set preparation\n",
    "key_2_train = july_small_poked[\"key_2\"]\n",
    "key_3_train = july_small_poked[\"key_3\"]\n",
    "target_train = july_small_poked[\"is_paid\"]\n",
    "y_train = july_small_poked[\"is_del\"]\n",
    "\n",
    "X_train = july_small_poked.drop([\"city_code\",\"l2_code\",\"com_id\",\"is_poked\",\"sales\",\"del_exp_cnt\",\"is_paid\",\"key_2\",\"key_3\"],axis = 1)\n",
    "\n",
    "\n",
    "X_cv, X_val, target_cv, target_val = train_test_split(X_train,target_train, test_size=0.3, random_state=18) \n",
    "\n",
    "y_cv = X_cv[\"is_del\"]\n",
    "y_val = X_val[\"is_del\"]\n",
    "\n",
    "X_train.drop(\"is_del\",axis = 1,inplace = True)\n",
    "X_cv.drop(\"is_del\",axis = 1,inplace = True)\n",
    "X_val.drop(\"is_del\",axis = 1,inplace = True)\n",
    "\n",
    "## test data preparation\n",
    "key_2_test = aug_small_bucket_poked[\"key_2\"]\n",
    "key_3_test = aug_small_bucket_poked[\"key_3\"]\n",
    "target_test = aug_small_bucket_poked[\"is_paid\"]\n",
    "y_test = aug_small_bucket_poked[\"is_del\"]\n",
    "\n",
    "X_test = aug_small_bucket_poked.drop([\"city_code\",\"l2_code\",\"com_id\",\"is_del\",\"is_poked\",\"sales\",\"del_exp_cnt\",\"is_paid\",\"key_2\",\"key_3\"],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4, 5, 6, 7, 8]]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(3,9))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'xgbclassifier__subsample': 0.6, 'xgbclassifier__reg_alpha': 0, 'xgbclassifier__random_state': 68, 'xgbclassifier__n_estimatorsf': 70, 'xgbclassifier__min_child_weight': 4, 'xgbclassifier__max_depth': 8, 'xgbclassifier__gamma': 10, 'xgbclassifier__eta': 0.1, 'xgbclassifier__colsample_bytree': 0.6, 'xgbclassifier__booster': 'gbtree', 'pca__n_components': 60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'standardscaler', 'pca', 'xgbclassifier', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'xgbclassifier__objective', 'xgbclassifier__use_label_encoder', 'xgbclassifier__base_score', 'xgbclassifier__booster', 'xgbclassifier__colsample_bylevel', 'xgbclassifier__colsample_bynode', 'xgbclassifier__colsample_bytree', 'xgbclassifier__gamma', 'xgbclassifier__gpu_id', 'xgbclassifier__importance_type', 'xgbclassifier__interaction_constraints', 'xgbclassifier__learning_rate', 'xgbclassifier__max_delta_step', 'xgbclassifier__max_depth', 'xgbclassifier__min_child_weight', 'xgbclassifier__missing', 'xgbclassifier__monotone_constraints', 'xgbclassifier__n_estimators', 'xgbclassifier__n_jobs', 'xgbclassifier__num_parallel_tree', 'xgbclassifier__random_state', 'xgbclassifier__reg_alpha', 'xgbclassifier__reg_lambda', 'xgbclassifier__scale_pos_weight', 'xgbclassifier__subsample', 'xgbclassifier__tree_method', 'xgbclassifier__validate_parameters', 'xgbclassifier__verbosity'])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:14:15] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('standardscaler',\n",
       "                                              StandardScaler()),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('xgbclassifier',\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            gamma=None,\n",
       "                                                            gpu_id=None,\n",
       "                                                            importance_type='gain',\n",
       "                                                            interaction_constraints=None,\n",
       "                                                            learning_rate=None,\n",
       "                                                            max_delta_step=None,\n",
       "                                                            max_depth...\n",
       "                                        'xgbclassifier__eta': [0.1, 0.2],\n",
       "                                        'xgbclassifier__gamma': [0, 1, 5, 7,\n",
       "                                                                 10],\n",
       "                                        'xgbclassifier__max_depth': [3, 4, 5, 6,\n",
       "                                                                     7, 8],\n",
       "                                        'xgbclassifier__min_child_weight': [3,\n",
       "                                                                            4,\n",
       "                                                                            5,\n",
       "                                                                            6,\n",
       "                                                                            7,\n",
       "                                                                            8],\n",
       "                                        'xgbclassifier__n_estimators': [30, 50,\n",
       "                                                                        70, 90,\n",
       "                                                                        120,\n",
       "                                                                        150,\n",
       "                                                                        200],\n",
       "                                        'xgbclassifier__random_state': [68],\n",
       "                                        'xgbclassifier__reg_alpha': [0, 0.01,\n",
       "                                                                     0.05],\n",
       "                                        'xgbclassifier__subsample': [0.6, 0.7,\n",
       "                                                                     0.8, 0.9,\n",
       "                                                                     1.0]},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    PCA(), \n",
    "    XGBClassifier()\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [10,20,30,40,50,60],\n",
    "    'xgbclassifier__n_estimators': [30, 50,70,90,120,150,200],\n",
    "    'xgbclassifier__min_child_weight':list(range(3,9)),\n",
    "    'xgbclassifier__booster':[\"gbtree\"],\n",
    "    'xgbclassifier__max_depth':list(range(3,9)),\n",
    "    'xgbclassifier__gamma': [0,1,5,7,10],              #***\n",
    "    'xgbclassifier__subsample': [round(0.1*i,2) for i in range(6,11)],    #**\n",
    "    'xgbclassifier__colsample_bytree': [round(0.1*i,2) for i in range(6,11)],  #**\n",
    "    'xgbclassifier__eta': [0.1,0.2], #*\n",
    "    'xgbclassifier__reg_alpha':[0,0.01, 0.05],#*\n",
    "    'xgbclassifier__random_state':[68]\n",
    "}\n",
    "\n",
    "n_iter = 68\n",
    "\n",
    "rdmsearch = RandomizedSearchCV(pipe, param_distributions=param_grid,n_jobs=-1,scoring = 'roc_auc', n_iter=n_iter,cv=5)\n",
    "rdmsearch.fit(X_cv, target_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:56] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:30:56] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The selected set of hyperparameters[xgb] is {'xgbclassifier__subsample': 0.6, 'xgbclassifier__reg_alpha': 0, 'xgbclassifier__random_state': 68, 'xgbclassifier__n_estimators': 200, 'xgbclassifier__min_child_weight': 4, 'xgbclassifier__max_depth': 8, 'xgbclassifier__gamma': 10, 'xgbclassifier__eta': 0.1, 'xgbclassifier__colsample_bytree': 0.9, 'xgbclassifier__booster': 'gbtree', 'pca__n_components': 10}.\n",
      "---The metric scores of the validation set is---\n",
      "Precision = 0.495,Recall = 0.375, F_score = 0.483\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:31:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:31:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "---The metric scores of the test set is---\n",
      "Precision = 0.491,Recall = 0.368, F_score = 0.478\n",
      "--- 206.79575300216675 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model_train(pipe,param_grid,n_iter,X_train,y_train,target_train,X_cv,y_cv,target_cv,X_val,y_val,target_val,X_test,y_test,target_test,plot_fea = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'min_samples_split':[2,3,5,6,8,10,12],\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [i for i in range(1,6)],\n",
    "    'max_features': [i for i in range(6,12)],\n",
    "    'min_samples_leaf': [3,4,5,6,7],\n",
    "    'min_samples_split': [2,3,5,6],\n",
    "    'n_estimators': [300,500,800],\n",
    "    \"class_weight\":[\"balanced\",\"balanced_subsample\"]\n",
    "}\n",
    "\n",
    "clf_3 = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdmsearch.fit(X_cv, target_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_val = np.array(rdmsearch.predict_proba(X_val)[:,1])\n",
    "\n",
    "interval = 0.2/10000\n",
    "threshold = [0.4 + i*interval for i in range(10001)]\n",
    "\n",
    "frame = pd.DataFrame()\n",
    "\n",
    "for i in threshold:    \n",
    "    scores_cla = [1 if j > i else 0 for j in prob_val]\n",
    "\n",
    "    scores_val = list(scores_cla)\n",
    "    label_val = list(target_val)\n",
    "\n",
    "    cl = stats_met(label_val,scores_val)\n",
    "\n",
    "    precision = cl.precision()\n",
    "\n",
    "    recall = cl.recall()\n",
    "\n",
    "    f_beta = cl.f_beta(beta = 0.3)\n",
    "\n",
    "    frame_row = {\"threshold\":i,\"Precision\":precision,\"Recall\":recall,\"F_beta\":f_beta}\n",
    "    frame = frame.append(frame_row,ignore_index=True)\n",
    "\n",
    "\n",
    "threshold_max = frame.loc[frame.F_beta == max(frame.F_beta),\"threshold\"].iloc[0]\n",
    "\n",
    "scores_val = [1 if j > threshold_max else 0 for j in prob_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49602"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:29:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { n_estimatorsf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:29:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('standardscaler',\n",
       "                                              StandardScaler()),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('xgbclassifier',\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            gamma=None,\n",
       "                                                            gpu_id=None,\n",
       "                                                            importance_type='gain',\n",
       "                                                            interaction_constraints=None,\n",
       "                                                            learning_rate=None,\n",
       "                                                            max_delta_step=None,\n",
       "                                                            max_depth...\n",
       "                                        'xgbclassifier__eta': [0.1, 0.2],\n",
       "                                        'xgbclassifier__gamma': [0, 1, 5, 7,\n",
       "                                                                 10],\n",
       "                                        'xgbclassifier__max_depth': [3, 4, 5, 6,\n",
       "                                                                     7, 8],\n",
       "                                        'xgbclassifier__min_child_weight': [3,\n",
       "                                                                            4,\n",
       "                                                                            5,\n",
       "                                                                            6,\n",
       "                                                                            7,\n",
       "                                                                            8],\n",
       "                                        'xgbclassifier__n_estimatorsf': [30, 50,\n",
       "                                                                         70, 90,\n",
       "                                                                         120,\n",
       "                                                                         150,\n",
       "                                                                         200],\n",
       "                                        'xgbclassifier__random_state': [68],\n",
       "                                        'xgbclassifier__reg_alpha': [0, 0.01,\n",
       "                                                                     0.05],\n",
       "                                        'xgbclassifier__subsample': [0.6, 0.7,\n",
       "                                                                     0.8, 0.9,\n",
       "                                                                     1.0]},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdmsearch.fit(X_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = list(rdmsearch.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [1 if j > threshold_max else 0 for j in pred_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.483,Recall = 0.347, F_score = 0.468\n"
     ]
    }
   ],
   "source": [
    "stats_met(labels,scores).get_eval_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
